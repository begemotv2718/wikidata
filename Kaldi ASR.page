---
categories: speech_recognition
...

* [Main site](http://kaldi-asr.org/)
* [Github link](https://github.com/kaldi-asr/kaldi/)
    * [Recipies for voxforge](https://github.com/kaldi-asr/kaldi/)
    * [Models](http://kaldi-asr.org/models.html)

* [Useful thesis describing some inner work of Kaldi](www.diplomovaprace.cz/133/thesis_oplatek.pdf)  Saved in papers
* [Offline transcriber for Estonian based on Kaldi alumae](https://github.com/alumae/kaldi-offline-transcriber) Use makefiles and some ad-hoc libraries in Java, python, etc.
* [Kaldi lectures by author](https://sites.google.com/site/dpovey/kaldi-lectures)

# User friendliness of Kaldi community

* [Thread in mail group](https://groups.google.com/forum/#!topic/kaldi-help/xs4wSKSK3vk)

Summary: 
We could probably add a page with documentation for people who don't know about speech recognition, but I don't put a high priority on it right now, as I am working on speed and accuracy improvements that are likely to have much more impact (and would also invalidate some of the documentation).
Also, without the kind of deep understanding that can only come from years of experience (or access to such a person), people like you are bound to run into problems that can't be fixed without help from someone more experienced.  It becomes unsustainable for me because there become too many questions.
There are plenty of students or other people out there who would be quite able to show you what to do and give you the help you need; they just don't have experience in setting up consulting arrangements; and in addition the bulk of them are either overseas or they don't have the type of visa that would allow them to officially work in the US.  You would have to help them navigate these issues somehow.  I can give you some names if you want, or vet people who contact you.

# Some concepts

## LDA

* Most probably stands for [Linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis), extracting components from gaussian mixture.

## Lattice decoder

Lattice apparently something that has multiple possible decoding path in it. 

Lattice
: The lattice is a finite-state transducer whose input and output labels are whatever labels were on the FST (typically transition-ids and words, respectively), and whose weights contain the acoustic, language model and transition weights

## Decoders

Not every decoder generate fully fledged lattice

* Simple
    * gmm-decode-simple
* Faster
    * gmm-decode-faster
* Lattice generating

gmm-decode-kaldi

gmm-decode-faster-fmllr ??

### gmm-latgen-faster

```gmm-latgen-faster [opts] <model-in> <fst-in|fst-rspecifier> <features-rspecifier> <lattice-wspecifier>```

```<model-in>``` is a file of type ```*.mdl```

Example of usage

```{.bash}
feats="ark,s,cs:apply-cmvn $cmvn_opts --utt2spk=ark:$sdata/JOB/utt2spk scp:<script file>"
# ark,s,cs -- s,cs means keys sorted on input
gmm-latgen-faster --beam=$beam=13.0 \
                  --lattice-beam=$lattice_beam=6.0 \
                  --acoustic-scale=$acwt=0.08333 \
                  --allow-partial=true \
                  --word-symbol-table=${graphdir}/words.txt=exp/tri1/graph/words.txt \
                  $model=${srcdir}/final.mdl=exp/tri1/final.mdl
                  $graphdir/HCLG.fst
                  "$feats"
                  "ark:gzip -c $dir/lat.JOB.gz"="ark:gzip -c exp/tri1/decode/lat.0.gz"

```    
              
* HCLG file (fst-in) is actually a construction composed of 4 FSTs [See Some notes on Kaldi](http://jrmeyer.github.io/kaldi/2016/02/01/Kaldi-notes.html)
    * L.fst: The Phonetic Dictionary FST
    * G.fst: The Language Model FST. FSA grammar (can be built from an n-gram grammar).
    * C.fst: The Context FST. C maps triphone sequences to monophones. Expands the phones into context-dependent phones.
    * H.fst: The HMM FST. H maps multiple HMM states (a.k.a. transition-ids in Kaldi-speak) to context-dependent triphones. Expands out the HMMs. On the right are the context-dependent phones and on the left are the pdf-ids.
    * HCLG file is compiled using shell script ```mkgraph.sh```


## Processing after decoding

```
lattice-best-path --lm-scale=11 --word-symbol-table=exp/tri2b/graph/words.txt "ark:gunzip -c exp/tri2b/decode/lat.*.gz|" ark,t:- 1>/dev/null
```

This generates '*.tra' files.

The '*.tra' files can be further processed with perl script ```int2sym.pl```

# Kaldi for russian 

* [s5 files for russian voxforge, etc.](https://github.com/freerussianasr/recipes)
* [Step by step recipe](https://github.com/grib0ed0v/kaldi-for-russian)


# Preparing language model: action by file

* ```local/voxforge_prepare_lm.sh```  
    * Run srilm on ```data/local/{train,test}_trans.txt```
    * Generates ```data/local/lm.arpa``` and ```data/local/vocab-full.txt```

* ```local/voxforge_prepare_dict.sh```
    * Download cmu_dict
    * Prepare lexicon.txt, vocab.txt, etc. using sequitur. Mostly operations on dictionary generating language files
    * Uses cmu_dict and ```data/local/vocab-full.txt```

* ``` utils/prepare_lang.sh```
    * Input dependencies????
    * Generate ```L.fst``` and ```L_disambig.fst``` and many other useful files in data/lang

* ```local/voxforge_format_data.sh```
    * Presumably, input files ```data/local/lm.arpa,data/lang/words.txt,data/local/dict/lexicon.txt``` output file 
    * calling ```arpa2fst``` to generate G.fst. Input files: data/local/lm.arpa and data/lang/words.txt  
    * Run diagnostics that the generated G.fst does not have cycles with empty words in them (also requires file data/local/dict/lexicon.txt) 
    * copies a lot of files (including L.fst, L_disambig.fst, phones, etc into ```data/lang_test/```

## Additional notes

* Librispeech training seemingly use external language model


# FSTs for language models

## Using jsgf models

* [Main info from here](https://groups.google.com/forum/#!topic/kaldi-help/9r6mea7aJVc)

**Summary**

* sphinx has ```sphinx_jsgf2fsg``` tool. ```sphinxbase/src/sphinx_jsgf2fsg/.libs/sphinx_jsgf2fsg```
* Openfst has ```fstcompile```
* [Vasily Panayotov explanation of decoding graphs](http://vpanayotov.blogspot.com.by/2012/06/kaldi-decoding-graph-construction.html) 


# Adding nnet models

* [Page on kaldi wiki: Deep neural networks in kaldi](http://kaldi-asr.org/doc/dnn.html) Minimal information (nnet -- first generation model, nnet2 -- second, nnet3 -- newest). Links to papers. Models are mutually incompatible.

## Transposing russian model to nnet3.

Russian model use only first generation nnet. The script ```voxforge_ru/local/nnet/run_dnn.sh``` can be compared to ```run_dnn.sh``` in other directories. 

The minimally differing examples: 

* 4% ```hkust/s5/local/nnet/run_dnn.sh```
* 5% ```tedlium/s5/local/nnet/run_dnn.sh```
* 5% ```swbd/s5b/local/nnet/run_dnn.sh```

These models have nnet3 also implemented. We should check how nnet3 script is invoked in training these models and then copy this to voxforge_ru.

Tedlium doesn't have nnet3 script embedded into ```run.sh```, it rather have ```local/nnet3/README``` with the following recipe:

* run.sh
* local/nnet3/run_tdnn.sh
* local/nnet3/run_tdnn_discriminative.sh

# NVIDIA acceleration for Kaldi

* [NVIDIA Accelerates Real Time Speech to Text Transcription 3500x with Kaldi | NVIDIA Developer Blog](https://devblogs.nvidia.com/nvidia-accelerates-speech-text-transcription-3500x-kaldi/) they claim rather enormous acceleration (like 3500Ñ…). [Their patch on github](https://github.com/kaldi-asr/kaldi/pull/3114)